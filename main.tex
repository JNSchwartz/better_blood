\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Efficient categorization of white blood cells by utilizing ResNet50V2 in the
4B-AdditionNet-based CNN network and ant colony optimization workflow\\
{\footnotesize \textsuperscript{*}Note: This paper is the result of a research practice course handout, the results are made up}
}

\author{\IEEEauthorblockN{1\textsuperscript{th} Bustya Balázs}
\IEEEauthorblockA{\textit{Eötvös Loránd University} \\
\textit{Faculty of Informatics}\\
Budapest, Hungary}
\and
\IEEEauthorblockN{2\textsuperscript{th} Csizmadia Árpád}
\IEEEauthorblockA{\textit{Eötvös Loránd University} \\
\textit{Faculty of Informatics}\\
Budapest, Hungary}
\and
\IEEEauthorblockN{3\textsuperscript{th} Nagy Norbert Botond}
\IEEEauthorblockA{\textit{Eötvös Loránd University} \\
\textit{Faculty of Informatics}\\
Budapest, Hungary}
\and
\IEEEauthorblockN{4\textsuperscript{th} Novák-Schwartz József}
\IEEEauthorblockA{\textit{Eötvös Loránd University)} \\
\textit{Faculty of Informatics}\\
Budapest, Hungary}
}

\maketitle

\begin{abstract}
The most logical healthcare method is prevention. Analyzing blood samples is an efficient way to discover serious health issues at early stage. 
Based on the count and the distribution of different types of white blood cells (WBC) early diagnosis of severe diseases, like leukemia and others, can be established. 
But process of manual blood sample analysis is very time consuming and costly. To solve this problem researchers have started to build automatic WBC counting and classification 
systems by using machine learning and deep learning technics. Image classification has developed significantly after appearing modern convolutional neural network (CNN) architectures. 
Researchers have achieved better and better results, but there is still room to improve the accuracy and especially the efficiency of the existing models. 
In this research the proposed system, includes the following methodologies: contrast limited adaptive histogram equalization (CLAHE) for preprocessing, 
combination of three networks, namely EfficientNetB0, 4B-AdditionNet and ResNet50V2 for feature extraction, ant colony optimization (ACO) for feature selection and multiple classifiers 
for classification of the WBS images.The chosen dataset is the Blood Cell Images, which is the augmented version of the BCCD  available dataset. The achieved results show nearly the same accuracy, as other state of the art systems, but reduced the run time with one order of magnitude.

\end{abstract}

\begin{IEEEkeywords}
White blood cells · CNN · Classification · Blood Cell Images dataset · Feature extraction · ResNet50V2
\end{IEEEkeywords}

\input{introduction.tex}

\section{Literature review}
Until nowadays, a lot of researches has been conducted on WBC image classification, which indicates the importance of the topic.
The \cite{b7} survey gives a very good introduction and overview of the more significant researches. It presents a wide spectrum of different technics and methodologies used by researchers to create semi or fully automatic systems for WBC counting and classification. The survey lists state of the art implementations categorized by the used methodologies based on the reached accuracy.

The WBS detection process with CNN is structured from 4 main steps: preprocessing, feature extraction, feature selection and classification.

Preprocessing have the role to remove irrelevant information from the image and enhance the contrast \cite{b8}, \cite{b9}, \cite{b10}, \cite{b11}. Good preprocessing can significantly improve the accuracy of the classification \cite{b12}.

CNN can be used for classification, but also for feature extraction (FE). FE is the process of extracting relevant information from raw data. However, 
the problem of extracting appropriate features that can reflect the intrinsic content of a piece of data or dataset as complete as possible is still a challenge for most FE techniques \cite{b13}. 
Shape color and texture features can be obtained with traditional image processing approach, but they are also present in sublayers of pretained CNNs like AlexNet.
In \cite{b14} study a traditional image processing approach and CNN (FE) with AlexNet is compared. Both approaches have comparable accuracy but misclassification is 
more in case of the traditional approach compared to the CNN approach. However CNN approach require more computational resources.

Feature selection (FS) is the process of removing the redundant or not important features from the output feature set of the FE. FS is very important to achieve high accuracy and deacreased runtime. 
The selection of redundant or innapropiate features results in low accuracy. Using lots of feature increases the runtime significantly \cite{b15}, \cite{b16}.

Classification is the final and most important stage. At this level every image gets the label of that class, which has the highest probability to correspond to the image \cite{b17}. 
The probability is usually calculated by using the softmax activation function. This function returns a number between 0 and 1 \cite{b18}. 

This paragraph contains a brief overview and comparison of state of the art systems.  
In \cite{b19} a color space conversion and k-means algorithm based new WBC nucleus segmentation method has been developed. The achieved accuracy is 99.42\% on BCCD dataset.
Paper \cite{b20} investigates image transformation operations and generative adversarial networks for data augmentation and state-of-the-art deep neural networks for classification. The achieved accuracy is 98.8\% using DenseNet-169 on CIFAR-100 dataset.
In \cite{b21} research a three step method is proposed: detecting the nucleus and cytoplasm with a new algorithm, extracting features, and classification using SVM model. The achieved accuracy is 94.20\% on BCCD dataset.
In \cite{b5} research the system contains contrast-limited adaptive histogram equalization as preprocessor; ResNet50, EfficientNetB0 and 4B-AdditionNet a for feature extraction; 
ant colony optimization for feature selection and support vector machine as well as quadratic discriminant analysis for classification. The achieved accuracy is 98.44\% on Blood Cell Images dataset.

The proposed CNN architecture in this research is very similar to the \cite{b5} papers CNN arhitecture, with modifications in the feature extraction process. 
The modification includes replacing the ResNet50 to ResNet50V2. ResNet50V2 is a modified version of ResNet50. ResNet50V2 was used in different medical application with success: 
\cite{b22} for histological analysis of breast tissue, \cite{b23} for detection of autism spectrum disorders on Resting-state Functional Magnetic Resonance Images 
\cite{b6} for detecting COVID-19 and pneumonia from chest X-ray images.


\input{methods.tex}
\input{dataset.tex}
\section{Execution environment}
The training process were conducted on a Windows 11 desktop PC with a AMD Ryzen 9 7950X with 16 cores and 32 threads. The CPU was overclocked to a base clock of 4.7 Ghz and we achieved a respectable 5.9 Ghz single core boost performance. The PC had 16GBs of DDR4-4400 RAM, and a CUDA enabled Nvidia GeForce GTX rtx 3090 GPU with 24 GBs of Video RAM (VRAM). Our system consumed 900W of power. The network design, testing, training, and the final experimentation process were performed using the MATLAB R2020b software package.
\section{Results and discussion}

The main objective of this study is to classify WBCs with improved performance while keeping the best possible accuracy while utilizing ResNet50V2 instead of ResNet50 in the classification pipeline discussed earlier (Sec. \ref{methods}) and reducing the number of features needed.
The following subsections contain the outcome and assessment of the performed experiments and they are subsequently explained in detail.

\subsection{Test No. 1 (2100 features)}
For this test we kept the original feature size to compare the result from (papaer1).
This test contains a total of 2100 features with 600 from 4B-AdditionNet, 900 from ResNet50, and 600 from EfficientNetB0. 
The final feature vector after fusion is of size $9957*2100$.
We achieved an Ac of 97.58\% with a Se of 96.56\%, Sp of 98.24\%, Pr of 94.85\%, and an F1 score of 95.69\%, with a runtime of 14.73 s. 
Figure \ref{test1} shows the detailed results for the classifiers, it illustrates the training time and Accuracy for all six classifiers.
Our accuracy is close to the original, but our runtime decreased almost tenfold.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[scale=0.25]{test1.png}
    \end{center}
    \caption{Test No.1 Results}
    \label{test1}
\end{figure}

\subsection{Test No. 2 (1600 features)}

For this test we kept the original feature size to compare the result from (papaer1).
This test contains a total of 1600 features with 500 from 4B-AdditionNet, 700 from ResNet50, and 400 from EfficientNetB0. 
The final feature vector after fusion is of size $9957*1600$.
We achieved an Ac of 96.58\% with a Se of 95.56\%, Sp of 97.24\%, Pr of 93.85\%, and an F1 score of 94.69\%, with a runtime of 13.73 s. 
Figure \ref{test1} shows the detailed results for the classifiers, it illustrates the training time and Accuracy for all six classifiers.
This test contained less features, which resulted in worse accuracy, however we didn't gain too much performance.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[scale=0.25]{test2.png}
    \end{center}
    \caption{Test No.2 Results}
    \label{test2}
\end{figure}

\subsection{Test No. 3 (1200 features)}

For this test we kept the original feature size to compare the result from (papaer1).
This test contains a total of 1200 features with 400 from 4B-AdditionNet, 400 from ResNet50, and 400 from EfficientNetB0. 
The final feature vector after fusion is of size $9957*1200$.
We achieved an Ac of 95.58\% with a Se of 94.56\%, Sp of 96.24\%, Pr of 92.85\%, and an F1 score of 93.69\%, with a runtime of 12.73 s. 
Figure \ref{test1} shows the detailed results for the classifiers, it illustrates the training time and Accuracy for all six classifiers.
This test contained much less features, which resulted in even worse accuracy, however we didn't gain too much performance.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[scale=0.25]{test3.png}
    \end{center}
    \caption{Test No.3 Results}
    \label{test3}
\end{figure}

\section{Conclusion}

We achieved 10 fold runtime decrease with ResNet50V2 using 2100 feature sets while keeping accuracy close to the original.
From the tests No. 2 and No. 3 we conclude that replacing ResNet50 with ResNet50V2 is a good way to decrease runtime while keeping good accuracy, but from the results we observed that the new method is sensitive to low feature sizes.
However for feature reduction we observed a negative result for runtime improvement, meaning that the original feature sizes are also performance optimal in the current pipeline.

\section{Future work}

While existing methods already achieved very high accuracy in blood cell classification, other aspects as speed and generality could be still improved as shown by this study. 
Further advances can be made by including and fusing together bigger Blood Cell Images datasets, like LISC, which would include an other type of cell to classify, which could refine our classification method to perform better across diverse datasets.
Performance can also be further improved by using bigger and more diverse datasets and by reducing the
amount of extracted features.

\section*{Acknowledgment}

We would like to say thank you to our research methodology practice teacher Turcsányi-Szabó Márta and lecturer Dr. Horváth Zoltán, who teached us the paper writing methodology and guided us with good advices.
We are grateful to Eötvös Loránd Tudományegyetem for providing us accessibility to the newest and most prestigious research journals.
This work would not have been possible without the supervision of the bravest and frendliest guard dog Maya, who always encouraged us to work hard.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[scale=0.16]{IMG_20221019_165459.jpg}
    \end{center}
    \caption{Maya is our patronus.}
\end{figure}


\section*{Peer review certification}
This paper went through a robust peer review process by anonymous field experts (Fig. \ref{aiProf}).

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[scale=0.10]{peer_review.png}
    \end{center}
    \caption{Unknown AI professional.}
    \label{aiProf}
\end{figure}

\section*{Declarations}

\textbf{Conflict of interest} On behalf of all authors, the corresponding author
states that there is no conflict of interest.

\begin{thebibliography}{00}
\bibitem{b1} BUSNATU, Ștefan, et al. Clinical Applications of Artificial Intelligence—An Updated Overview. Journal of Clinical Medicine, 2022, 11.8: 2265.
\bibitem{b2} PFEIL, Juliane, et al. Examination of blood samples using deep learning and mobile microscopy. BMC bioinformatics, 2022, 23.1: 1-14.
\bibitem{b3} HUANG, Qian, et al. Blood cell classification based on hyperspectral imaging with modulated Gabor and CNN. IEEE journal of biomedical and health informatics, 2019, 24.1: 160-170.
\bibitem{b4} BOLDÚ, Laura, et al. A deep learning model (ALNet) for the diagnosis of acute leukaemia lineage using peripheral blood cell images. Computer Methods and Programs in Biomedicine, 2021, 202: 105999.
\bibitem{b5} SHAHZAD, Asim, et al. Categorizing white blood cells by utilizing deep features of proposed 4B-AdditionNet-based CNN network with ant colony optimization. Complex and Intelligent Systems, 2022, 8.4: 3143-3159.
\bibitem{b6} RAHIMZADEH, Mohammad; ATTAR, Abolfazl. A modified deep convolutional neural network for detecting COVID-19 and pneumonia from chest X-ray images based on the concatenation of Xception and ResNet50V2. Informatics in medicine unlocked, 2020, 19: 100360.
\bibitem{b7} KHAN, Siraj, et al. A review on traditional machine learning and deep learning models for WBCs classification in blood smear images. IEEE Access, 2020, 9: 10657-10673.
\bibitem{b8} TAVAKOLI, Nasrin, et al. Detection of abnormalities in mammograms using deep features. Journal of Ambient Intelligence and Humanized Computing, 2019, 1-13. 
\bibitem{b9} PRINYAKUPT, Jaroonrut; PLUEMPITIWIRIYAWEJ, Charnchai. Segmentation of white blood cells and comparison of cell morphology by linear and naïve Bayes classifiers. Biomedical engineering online, 2015, 14.1: 1-19. 
\bibitem{b10} JIANG, Kan; LIAO, Qing-Min; XIONG, Yuan. A novel white blood cell segmentation scheme based on feature space clustering. Soft Computing, 2006, 10.1: 12-19.
\bibitem{b11} ZHONG, Zhen, et al. White blood cell segmentation via sparsity and geometry constraints. IEEE Access, 2019, 7: 167593-167604.
\bibitem{b12} PAL, Kuntal Kumar; SUDEEP, K. S. Preprocessing for image classification by convolutional neural networks. In: 2016 IEEE International Conference on Recent Trends in Electronics, Information and Communication Technology (RTEICT). IEEE, 2016. p. 1778-1781.
\bibitem{b13} SALAU, Ayodeji Olalekan; JAIN, Shruti. Feature extraction: a survey of the types, techniques, applications. In: 2019 International Conference on Signal Processing \& Communication (ICSC). IEEE, 2019. p. 158-164.
\bibitem{b14} HEGDE, Roopa B., et al. Feature extraction using traditional image processing and convolutional neural network methods to classify white blood cells: a study. Australasian physical \& engineering sciences in medicine, 2019, 42.2: 627-638. 
\bibitem{b15} SHARIF, Muhammad, et al. A framework for offline signature verification system: Best features selection approach. Pattern Recognition Letters, 2020, 139: 50-59.
\bibitem{b16} SABA, Tanzila, et al. Categorizing the students’ activities for automated exam proctoring using proposed deep L2-GraftNet CNN network and ASO based feature selection approach. IEEE Access, 2021, 9: 47639-47656.
\bibitem{b17} SHAH, Jamal Hussain, et al. Facial expressions classification and false label reduction using LDA and threefold SVM. Pattern Recognition Letters, 2020, 139: 166-173.
\bibitem{b18} BRIDLE, John S. Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. In: Neurocomputing. Springer, Berlin, Heidelberg, 1990. p. 227-236.
\bibitem{b19} BANIK, Partha Pratim; SAHA, Rappy; KIM, Ki-Doo. An automatic nucleus segmentation and CNN model based classification method of white blood cell. Expert Systems with Applications, 2020, 149: 113211. 
\bibitem{b20} ALMEZHGHWI, Khaled; SERTE, Sertan. Improved classification of white blood cells with the generative adversarial network and deep convolutional neural network. Computational Intelligence and Neuroscience, 2020, 2020.
\bibitem{b21} TAVAKOLI, Sajad, et al. New segmentation and feature extraction algorithm for classification of white blood cells in peripheral smear images. Scientific Reports, 2021, 11.1: 1-13.
\bibitem{b22} FERREIRA, Carlos A., et al. Classification of breast cancer histology images through transfer learning using a pre-trained inception resnet v2. In: International conference image analysis and recognition. Springer, Cham, 2018. p. 763-770. 
\bibitem{b23} DOMINIC, Nicholas, et al. Transfer learning using inception-ResNet-v2 model to the augmented neuroimages data for autism spectrum disorder classification. Commun. Math. Biol. Neurosci., 2021, 2021: Article ID 39. 
\bibitem{SVM} Cortes, C., Vapnik, V. Support-vector networks. Mach Learn 20, 273–297 (1995). https://doi.org/10.1007/BF00994018
\bibitem{LDA} R. A. FISHER, The use of multiple measurements in taxonomic problems. Annals of Eugenics Volume 7, Issue 2, Pages 87-193, 1936. https://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x
\bibitem{BloodCellImages} Blood Cell Images|Kaggle.. Available at. https://www.kaggle.com/paultimothymooney/blood-cells.
\bibitem{BCCD} Shenggan$/$BCCD_Dataset: BCCD (Blood Cell Count and Detection) Dataset is a small-scale dataset for blood cells detection. Accessed: Mar. 06, 2021. Available at https://github.com/Shenggan/BCCD_Dataset
\bibitem{AcuteLymphocyticLeukemia} K. K. Jha and H. S. Dutta, “Mutual Information based hybrid model and deep learning for Acute Lymphocytic Leukemia detection in single cell blood smear images,” Computer Methods and Programs in Biomedicine, vol. 179, p. 104987, Oct. 2019, doi: 10.1016/j.cmpb.2019.104987.
\bibitem{HemocytometerCounting} M. Absher, “CHAPTER 1 - Hemocytometer Counting,” in Tissue Culture, P. F. Kruse and M. K. Patterson, Eds. Academic Press, 1973, pp. 395–397. doi: 10.1016/B978-0-12-427150-0.50098-X.
\bibitem{CBC} R. Agarwal, A. Sarkar, A. Bhowmik, D. Mukherjee, and S. Chakraborty, “A portable spinning disc for complete blood count (CBC),” Biosensors and Bioelectronics, vol. 150, p. 111935, Feb. 2020, doi: 10.1016/j.bios.2019.111935.
\bibitem{CLAHE} A. W. Setiawan, T. R. Mengko, O. S. Santoso and A. B. Suksmono, "Color retinal image enhancement using CLAHE," International Conference on ICT for Smart Society, 2013, pp. 1-3, doi: 10.1109/ICTSS.2013.6588092.
\bibitem{ResNet50V2Better} M. Rahimzadeh and A. Attar, “A modified deep convolutional neural network for detecting COVID-19 and pneumonia from chest X-ray images based on the concatenation of Xception and ResNet50V2,” Informatics in Medicine Unlocked, vol. 19, p. 100360, Jan. 2020, doi: 10.1016/j.imu.2020.100360.

\end{thebibliography}
\vspace{12pt}
\color{red}
\end{document}

